import os

import streamlit as st
from utils import is_token_expired, extract_files
from langchain.agents import ConversationalChatAgent, AgentExecutor
from langchain.memory import ConversationBufferMemory
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.runnables import RunnableConfig
from langchain_community.chat_models import ChatTongyi

st.set_page_config(page_title="è®ºæ–‡é—®ç­”", page_icon="ğŸ¤–")
st.title('ğŸ¤–è®ºæ–‡é—®ç­”')


def show_chat(msgs):
    avatars = {"human": "user", "ai": "assistant"}
    for idx, msg in enumerate(msgs.messages):
        with st.chat_message(avatars[msg.type]):
            # Render intermediate steps if any were saved
            for step in st.session_state.steps.get(str(idx), []):
                if step[0].tool == "_Exception":
                    continue
                with st.status(f"**{step[0].tool}**: {step[0].tool_input}", state="complete"):
                    st.write(step[0].log)
                    st.write(step[1])
            st.write(msg.content)


def main():
    msgs = StreamlitChatMessageHistory()
    memory = ConversationBufferMemory(
        chat_memory=msgs, return_messages=True, memory_key="chat_history", output_key="output"
    )
    # é€šè¿‡ä¸‹æ‹‰æ¡†é€‰æ‹©æ–‡æ¡£
    document_names = [file['file_name'] for file in st.session_state['files']]
    selected_doc_name = st.selectbox("é€‰æ‹©æ–‡æ¡£", document_names)
    # æ ¹æ®é€‰å®šçš„æ–‡æ¡£åç§°ä»æ•°æ®åº“ä¸­è·å–å†…å®¹
    document_content = extract_files(st.session_state['files'][document_names.index(selected_doc_name)]['file_path'])
    # if document_content:
    #     st.write(f"å·²åŠ è½½æ–‡æ¡£ï¼š{selected_doc_name}")
    # else:
    #     st.write("å½“å‰æ— æ–‡æ¡£.")
    # å®šä¹‰ç³»ç»Ÿæç¤ºï¼Œä»¥æä¾›æ–‡æ¡£å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ª AI åŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š
    {document_content}

    å¦‚æœä½ æ— æ³•åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œå¯ä»¥è”ç½‘æœç´¢,å¹¶æŒ‡æ˜æ˜¯æœç´¢å¾—æ¥çš„ä¿¡æ¯ã€‚"""
    if len(msgs.messages) == 0 or st.sidebar.button("Reset chat history"):
        msgs.clear()
        msgs.add_ai_message(f"å½“å‰å·²åŠ è½½æ–‡æ¡£ {selected_doc_name},å¿«æ¥æé—®å§.")
        st.session_state.steps = {}
        system_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š
            {document_content}

            å¦‚æœä½ æ— æ³•åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œå¯ä»¥è”ç½‘æœç´¢,å¹¶æŒ‡æ˜æ˜¯æœç´¢å¾—æ¥çš„ä¿¡æ¯ã€‚"""
    show_chat(msgs)
    if prompt := st.chat_input():
        st.chat_message("user").write(prompt)
        llm = ChatTongyi(model_name="qwen-max", streaming=True)
        tools = [DuckDuckGoSearchRun(name="Search")]
        chat_agent = ConversationalChatAgent.from_llm_and_tools(llm=llm,
                                                                tools=tools,
                                                                system_prompt=system_prompt)
        executor = AgentExecutor.from_agent_and_tools(
            agent=chat_agent,
            tools=tools,
            memory=memory,
            return_intermediate_steps=True,
            handle_parsing_errors=True,
        )
        with st.chat_message("assistant"):
            st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=False)
            cfg = RunnableConfig()
            cfg["callbacks"] = [st_cb]
            response = executor.invoke(prompt, cfg)
            st.write(response["output"])
            st.session_state.steps[str(len(msgs.messages) - 1)] = response["intermediate_steps"]


if (not st.session_state['token']) or is_token_expired(st.session_state['token']):
    st.error('è¿˜æ²¡ç™»å½•å“¦')
elif not st.session_state.files:
    st.write('### è¿˜æ²¡ä¸Šä¼ æ–‡æ¡£å“¦')
else:
    main()
